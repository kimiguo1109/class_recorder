"""
è¯´è¯äººè¯†åˆ«æœåŠ¡ - ä½¿ç”¨å£°çº¹ç‰¹å¾è¯†åˆ«æ•™æˆå’Œå­¦ç”Ÿ
"""
import os
import json
import logging
import numpy as np
import torch
from typing import Dict, Optional, List, Tuple
import io
import wave

logger = logging.getLogger(__name__)

class SpeakerRecognitionService:
    """
    è¯´è¯äººè¯†åˆ«æœåŠ¡
    åŠŸèƒ½ï¼š
    1. å£°çº¹æ³¨å†Œï¼ˆå½•åˆ¶æ•™æˆå£°éŸ³æ ·æœ¬ï¼‰
    2. å®æ—¶å£°çº¹è¯†åˆ«ï¼ˆåˆ¤æ–­æ˜¯å¦æ˜¯æ•™æˆï¼‰
    3. å¤šè¯´è¯äººåŒºåˆ†
    """
    
    def __init__(self):
        self.embeddings_cache: Dict[str, np.ndarray] = {}  # ç¼“å­˜å£°çº¹ç‰¹å¾
        self.professor_embedding: Optional[np.ndarray] = None
        self.similarity_threshold = 0.7  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
        
        # å£°çº¹ç‰¹å¾æå–æ¨¡å‹ï¼ˆä½¿ç”¨ pyannote.audioï¼‰
        try:
            from pyannote.audio import Model
            from pyannote.audio.pipelines import SpeakerDiarization
            from pyannote.audio import Inference
            
            logger.info("ğŸ”„ Loading speaker embedding model...")
            
            # ä½¿ç”¨é¢„è®­ç»ƒçš„å£°çº¹ç‰¹å¾æå–æ¨¡å‹
            # è¿™ä¸ªæ¨¡å‹å¯ä»¥æå–è¯´è¯äººçš„å£°çº¹ç‰¹å¾å‘é‡
            self.embedding_model = Inference(
                "pyannote/embedding",
                window="whole"  # å¤„ç†æ•´ä¸ªéŸ³é¢‘ç‰‡æ®µ
            )
            
            logger.info("âœ… Speaker embedding model loaded")
            self.model_available = True
            
        except Exception as e:
            logger.warning(f"âš ï¸ Speaker recognition model not available: {e}")
            logger.info("ğŸ’¡ Falling back to simple energy-based detection")
            self.model_available = False
            self.embedding_model = None
        
        # åŠ è½½å·²ä¿å­˜çš„æ•™æˆå£°çº¹
        self._load_professor_embedding()
    
    def _load_professor_embedding(self):
        """ä»æ–‡ä»¶åŠ è½½æ•™æˆçš„å£°çº¹ç‰¹å¾"""
        embedding_file = "professor_embedding.npy"
        if os.path.exists(embedding_file):
            try:
                self.professor_embedding = np.load(embedding_file)
                logger.info(f"âœ… Loaded professor voice profile (shape: {self.professor_embedding.shape})")
            except Exception as e:
                logger.error(f"âŒ Failed to load professor embedding: {e}")
    
    def _save_professor_embedding(self):
        """ä¿å­˜æ•™æˆçš„å£°çº¹ç‰¹å¾åˆ°æ–‡ä»¶"""
        if self.professor_embedding is not None:
            try:
                np.save("professor_embedding.npy", self.professor_embedding)
                logger.info("âœ… Professor voice profile saved")
            except Exception as e:
                logger.error(f"âŒ Failed to save professor embedding: {e}")
    
    def extract_embedding(self, audio_data: np.ndarray, sample_rate: int = 16000) -> Optional[np.ndarray]:
        """
        æå–éŸ³é¢‘çš„å£°çº¹ç‰¹å¾å‘é‡
        
        å‚æ•°:
            audio_data: éŸ³é¢‘æ•°æ®ï¼ˆnumpy arrayï¼Œfloat32ï¼Œ[-1, 1]ï¼‰
            sample_rate: é‡‡æ ·ç‡ï¼ˆé»˜è®¤ 16000Hzï¼‰
        
        è¿”å›:
            å£°çº¹ç‰¹å¾å‘é‡ï¼ˆ512ç»´ï¼‰
        """
        if not self.model_available or self.embedding_model is None:
            # ä½¿ç”¨ç®€å•çš„éŸ³é¢‘ç‰¹å¾ï¼ˆèƒ½é‡ã€è¿‡é›¶ç‡ç­‰ï¼‰
            return self._extract_simple_features(audio_data)
        
        try:
            # ç¡®ä¿éŸ³é¢‘é•¿åº¦è‡³å°‘ 1 ç§’
            min_samples = sample_rate * 1  # 1ç§’
            if len(audio_data) < min_samples:
                # å¡«å……åˆ° 1 ç§’
                audio_data = np.pad(audio_data, (0, min_samples - len(audio_data)), 'constant')
            
            # pyannote éœ€è¦çš„æ ¼å¼ï¼š{"waveform": tensor, "sample_rate": int}
            audio_tensor = torch.from_numpy(audio_data).unsqueeze(0)  # æ·»åŠ  batch ç»´åº¦
            
            # æå–å£°çº¹ç‰¹å¾
            embedding = self.embedding_model({
                "waveform": audio_tensor,
                "sample_rate": sample_rate
            })
            
            # è½¬æ¢ä¸º numpy æ•°ç»„
            if isinstance(embedding, torch.Tensor):
                embedding = embedding.detach().cpu().numpy()
            
            # å½’ä¸€åŒ–ï¼ˆæ–¹ä¾¿åç»­è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
            embedding = embedding / (np.linalg.norm(embedding) + 1e-8)
            
            logger.debug(f"ğŸ“Š Extracted embedding shape: {embedding.shape}")
            return embedding
            
        except Exception as e:
            logger.error(f"âŒ Embedding extraction failed: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _extract_simple_features(self, audio_data: np.ndarray) -> np.ndarray:
        """
        æå–ç®€å•çš„éŸ³é¢‘ç‰¹å¾ï¼ˆåå¤‡æ–¹æ¡ˆï¼‰
        åŒ…æ‹¬ï¼šèƒ½é‡ã€è¿‡é›¶ç‡ã€é¢‘è°±è´¨å¿ƒç­‰
        """
        try:
            # 1. èƒ½é‡ï¼ˆRMSï¼‰
            energy = np.sqrt(np.mean(audio_data ** 2))
            
            # 2. è¿‡é›¶ç‡ï¼ˆZero Crossing Rateï¼‰
            zero_crossings = np.sum(np.abs(np.diff(np.sign(audio_data)))) / (2 * len(audio_data))
            
            # 3. é¢‘è°±è´¨å¿ƒï¼ˆéœ€è¦ FFTï¼‰
            fft = np.fft.rfft(audio_data)
            magnitude = np.abs(fft)
            freqs = np.fft.rfftfreq(len(audio_data), 1/16000)
            spectral_centroid = np.sum(freqs * magnitude) / (np.sum(magnitude) + 1e-8)
            
            # 4. é¢‘è°±å¸¦å®½
            spectral_bandwidth = np.sqrt(
                np.sum(((freqs - spectral_centroid) ** 2) * magnitude) / (np.sum(magnitude) + 1e-8)
            )
            
            # ç»„åˆæˆç‰¹å¾å‘é‡ï¼ˆ4ç»´ï¼Œéœ€è¦æ‰©å±•åˆ°æ›´é«˜ç»´åº¦ï¼‰
            simple_features = np.array([
                energy,
                zero_crossings,
                spectral_centroid / 8000,  # å½’ä¸€åŒ–
                spectral_bandwidth / 8000   # å½’ä¸€åŒ–
            ])
            
            # æ‰©å±•åˆ° 512 ç»´ï¼ˆé‡å¤ç‰¹å¾ï¼‰
            simple_features = np.tile(simple_features, 128)
            
            return simple_features
            
        except Exception as e:
            logger.error(f"âŒ Simple feature extraction failed: {e}")
            return np.random.rand(512)  # è¿”å›éšæœºå‘é‡ä½œä¸ºåå¤‡
    
    def register_professor_voice(self, audio_bytes: bytes) -> bool:
        """
        æ³¨å†Œæ•™æˆçš„å£°éŸ³ï¼ˆå½•åˆ¶æ ·æœ¬ï¼‰
        
        å‚æ•°:
            audio_bytes: éŸ³é¢‘æ•°æ®ï¼ˆPCMï¼Œ16-bitï¼Œ16kHzï¼Œmonoï¼‰
        
        è¿”å›:
            æ˜¯å¦æˆåŠŸæ³¨å†Œ
        """
        try:
            # è½¬æ¢ä¸º numpy æ•°ç»„
            audio_array = np.frombuffer(audio_bytes, dtype=np.int16)
            audio_float = audio_array.astype(np.float32) / 32768.0
            
            # æå–å£°çº¹ç‰¹å¾
            embedding = self.extract_embedding(audio_float)
            
            if embedding is None:
                logger.error("âŒ Failed to extract embedding for professor voice")
                return False
            
            # ä¿å­˜å£°çº¹ç‰¹å¾
            self.professor_embedding = embedding
            self._save_professor_embedding()
            
            logger.info(f"âœ… Professor voice registered (embedding shape: {embedding.shape})")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Professor voice registration failed: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def calculate_similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå£°çº¹ç‰¹å¾çš„ç›¸ä¼¼åº¦ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        
        è¿”å›:
            ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸åŒ
        """
        try:
            # ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(embedding1.flatten(), embedding2.flatten())
            # ç¡®ä¿åœ¨ [0, 1] èŒƒå›´å†…
            similarity = max(0, min(1, (similarity + 1) / 2))
            return float(similarity)
        except Exception as e:
            logger.error(f"âŒ Similarity calculation failed: {e}")
            return 0.0
    
    def identify_speaker(self, audio_bytes: bytes) -> Tuple[str, float]:
        """
        è¯†åˆ«è¯´è¯äººï¼ˆæ•™æˆ or å­¦ç”Ÿï¼‰
        
        å‚æ•°:
            audio_bytes: éŸ³é¢‘æ•°æ®ï¼ˆPCMï¼Œ16-bitï¼Œ16kHzï¼Œmonoï¼‰
        
        è¿”å›:
            (è¯´è¯äººç±»å‹, ç½®ä¿¡åº¦)
            - è¯´è¯äººç±»å‹: "professor" æˆ– "student" æˆ– "unknown"
            - ç½®ä¿¡åº¦: 0-1
        """
        try:
            # å¦‚æœæ²¡æœ‰æ³¨å†Œæ•™æˆå£°éŸ³ï¼Œè¿”å› unknown
            if self.professor_embedding is None:
                logger.debug("â„¹ï¸ No professor voice profile registered")
                return "unknown", 0.0
            
            # è½¬æ¢éŸ³é¢‘ä¸º numpy æ•°ç»„
            audio_array = np.frombuffer(audio_bytes, dtype=np.int16)
            audio_float = audio_array.astype(np.float32) / 32768.0
            
            # æ£€æŸ¥éŸ³é¢‘èƒ½é‡ï¼ˆè¿‡æ»¤é™éŸ³ï¼‰
            energy = np.sqrt(np.mean(audio_float ** 2))
            if energy < 0.01:
                logger.debug(f"ğŸ”‡ Silence detected (energy: {energy:.4f})")
                return "unknown", 0.0
            
            # æå–å½“å‰éŸ³é¢‘çš„å£°çº¹ç‰¹å¾
            current_embedding = self.extract_embedding(audio_float)
            
            if current_embedding is None:
                logger.error("âŒ Failed to extract embedding for current audio")
                return "unknown", 0.0
            
            # è®¡ç®—ä¸æ•™æˆå£°éŸ³çš„ç›¸ä¼¼åº¦
            similarity = self.calculate_similarity(current_embedding, self.professor_embedding)
            
            logger.debug(f"ğŸ“Š Speaker similarity: {similarity:.4f} (threshold: {self.similarity_threshold})")
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯æ•™æˆ
            if similarity >= self.similarity_threshold:
                return "professor", similarity
            else:
                return "student", 1.0 - similarity
            
        except Exception as e:
            logger.error(f"âŒ Speaker identification failed: {e}")
            import traceback
            traceback.print_exc()
            return "unknown", 0.0
    
    def has_professor_profile(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²æ³¨å†Œæ•™æˆå£°éŸ³"""
        return self.professor_embedding is not None
    
    def clear_professor_profile(self):
        """æ¸…é™¤æ•™æˆå£°éŸ³é…ç½®"""
        self.professor_embedding = None
        if os.path.exists("professor_embedding.npy"):
            os.remove("professor_embedding.npy")
        logger.info("âœ… Professor voice profile cleared")


# å…¨å±€å®ä¾‹
speaker_recognition_service = SpeakerRecognitionService()

